# Information Point Generation

<!--
Status: Draft
Created: 2025-11-30
Issue: #15 (Q3, Q4, Q5)
Owner: Harry
-->

> System specification for AI-generated Information Points, content formats, and quiz type assignment.

## Related Specifications

| Spec | Relationship |
|------|--------------|
| [Question Generation](./question-generation.md) | Uses IPs to generate quiz questions |
| [Learning & Interaction Modes](./learning-interaction-modes.md) | Modes that present IP content |
| [Course Structure & Navigation](./course-structure-navigation.md) | Hierarchy containing IPs |

## Overview

Information Points (IPs) are the atomic units of learning content. They are primarily generated by AI when courses are created, with human override capabilities.

### Core Principles

1. **AI-first**: IPs generated automatically from course topics/materials
2. **Rich content**: Support for text, code, math, and media
3. **Efficient AI context**: Media stored externally, AI receives text descriptions
4. **Flexible quiz types**: AI assigns appropriate quiz types, humans can override

---

## Content Model

### Hybrid Storage Approach

| Content Type | Storage | AI Processing |
|--------------|---------|---------------|
| Text (Markdown) | Database | Direct |
| Code blocks | Database | Direct |
| LaTeX/Math | Database (source) | Direct |
| Images | Google Cloud Storage | Description only |
| Audio | Google Cloud Storage | Transcript only |
| Diagrams | Google Cloud Storage | Description only |
| Videos | YouTube (external) | Transcript only |

### Data Model

```typescript
interface InformationPoint {
  id: string;
  lessonId: string;
  order: number;
  
  // Metadata
  title: string;
  type: 'definition' | 'concept' | 'procedure' | 'example';
  
  // Content (Markdown with asset placeholders)
  content: string;  // e.g., "Binary search:\n\n{{asset:diagram-123}}\n\nSteps:..."
  
  // Referenced assets
  assets: Asset[];
  
  // Pre-computed for AI (text-only, fast)
  aiContext: string;
  
  // Quiz configuration
  quizTypes: {
    available: QuizType[];
    assignedBy: 'ai' | 'human';
  };
  
  // Relationships (see Relationships section)
  prerequisites: string[];     // IPs required before this one (stored)
  dependents: string[];        // IPs that require this one (computed)
  relatedPoints: string[];     // Conceptually related, no order (stored)
}

type QuizType = 'binary' | 'multiple_choice' | 'question_answer' | 'comparison';
```

### Asset Model

```typescript
interface Asset {
  id: string;
  informationPointId: string;
  
  type: 'image' | 'video' | 'audio' | 'diagram';
  
  // Storage
  storage: {
    provider: 'gcs' | 'youtube';
    url: string;
    thumbnailUrl?: string;
  };
  
  // For AI (no media processing needed)
  aiMetadata: {
    description: string;     // Auto-generated or manual
    transcript?: string;     // For video/audio
    altText?: string;        // Accessibility
  };
  
  // Rendering hints
  display: {
    position: 'inline' | 'block';
    caption?: string;
    aspectRatio?: string;
  };
  
  // Metadata
  fileSize?: number;
  duration?: number;         // For video/audio (seconds)
  generatedAt?: Date;        // When AI metadata was generated
}
```

---

## AI Context Generation

When AI needs to understand an IP (for Learn Mode, Quiz generation, etc.), we build a **text-only context**:

```typescript
function buildAIContext(ip: InformationPoint): string {
  let context = ip.content;
  
  for (const asset of ip.assets) {
    const placeholder = `{{asset:${asset.id}}}`;
    let replacement = `[${asset.type.toUpperCase()}: ${asset.aiMetadata.description}]`;
    
    if (asset.aiMetadata.transcript) {
      replacement += `\n[Transcript: ${asset.aiMetadata.transcript}]`;
    }
    
    context = context.replace(placeholder, replacement);
  }
  
  return context;
}
```

**Example transformation:**

```markdown
// Original content
Binary search divides the search space in half repeatedly.

{{asset:diagram-bsearch-001}}

Here's the algorithm:
```

```markdown
// AI context
Binary search divides the search space in half repeatedly.

[DIAGRAM: Sorted array with left, mid, right pointers. Shows 3 iterations 
narrowing down to find target value 7. Arrows indicate comparison direction.]

Here's the algorithm:
```

---

## Asset Processing Pipeline

### On Upload

```
┌─────────────────────────────────────────────────────────────────┐
│  ASSET UPLOAD PIPELINE                                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  User uploads file                                              │
│         │                                                       │
│         ▼                                                       │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │  1. Upload to Google Cloud Storage                          ││
│  │     → Returns URL + thumbnailUrl                            ││
│  └──────────────────────────┬──────────────────────────────────┘│
│                             │                                   │
│                             ▼                                   │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │  2. Generate AI Metadata (async)                            ││
│  │                                                             ││
│  │  Image/Diagram → Gemini Vision → description                ││
│  │  Video → YouTube transcript OR Gemini 2.5 Flash → transcript││
│  │  Audio → Gemini 2.5 Flash → transcript                      ││
│  └──────────────────────────┬──────────────────────────────────┘│
│                             │                                   │
│                             ▼                                   │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │  3. Store Asset record with aiMetadata                      ││
│  │     → Regenerate parent IP's aiContext                      ││
│  └─────────────────────────────────────────────────────────────┘│
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Model Configuration

```typescript
const ASSET_AI_CONFIG = {
  imageDescription: {
    model: 'gemini-2.5-flash',  // Vision capable
    prompt: `Describe this image for a learning context. 
             Focus on educational content, diagrams, and key visual elements.
             Be concise but comprehensive.`,
    maxTokens: 256,
  },
  
  audioTranscription: {
    model: 'gemini-2.5-flash',
    maxDuration: 600,  // 10 minutes max
  },
  
  videoTranscription: {
    // Prefer YouTube auto-captions if available
    fallbackModel: 'gemini-2.5-flash',
    maxDuration: 1800,  // 30 minutes max
  },
};
```

---

## Quiz Type Assignment

### Default: AI Assignment

When an IP is created, AI analyzes content and assigns appropriate quiz types:

```typescript
interface QuizTypeAssignment {
  rules: {
    // Definitions → good for T/F and MC
    definition: ['binary', 'multiple_choice'],
    
    // Concepts → all types work
    concept: ['binary', 'multiple_choice', 'question_answer'],
    
    // Procedures → Q&A best for explaining steps
    procedure: ['multiple_choice', 'question_answer'],
    
    // Examples → MC for recognition
    example: ['multiple_choice'],
  };
}
```

### AI Assignment Prompt

```typescript
const QUIZ_TYPE_PROMPT = `
Analyze this Information Point and determine which quiz types are appropriate.

Information Point:
Title: {title}
Type: {type}
Content: {aiContext}

Consider:
- Binary (True/False): Good for facts, definitions, clear statements
- Multiple Choice: Good for recognition, comparison, selecting correct options
- Question & Answer: Good for explanation, procedures, deeper understanding

Return JSON: { "quizTypes": ["binary", "multiple_choice", "question_answer"] }
Only include types that genuinely fit this content.
`;
```

### Human Override

```typescript
interface QuizTypeOverride {
  // Human directly sets types
  manual: (ipId: string, types: QuizType[]) => void;
  
  // Human requests AI suggestion, then reviews
  requestSuggestion: (ipId: string) => Promise<QuizType[]>;
  approveSuggestion: (ipId: string, types: QuizType[]) => void;
}
```

---

## IP Relationships

Information Points have three types of relationships that power contextual learning and advanced quiz types.

### Relationship Types

| Type | Direction | Storage | Description |
|------|-----------|---------|-------------|
| `prerequisites` | Backward | Stored | IPs that must be learned before this one |
| `dependents` | Forward | Computed | IPs that build on this one |
| `relatedPoints` | Bidirectional | Stored | Conceptually related, no order requirement |

### Computing Dependents

`dependents` is derived from `prerequisites` to avoid maintaining bidirectional links:

```typescript
async function getDependents(ipId: string): Promise<string[]> {
  // Find all IPs where this IP is in their prerequisites
  return await db.informationPoint.findMany({
    where: { prerequisites: { has: ipId } },
    select: { id: true },
  }).then(ips => ips.map(ip => ip.id));
}

// Can be cached and invalidated when course structure changes
```

### Usage by Feature

| Feature | Prerequisites | Dependents | Related |
|---------|--------------|------------|---------|
| **Learn Mode** | "Building on X..." | "This enables Y..." | "Similar to Z..." |
| **Quiz: Comparison** | "How does Y build on X?" | Same | "Compare X and Y" |
| **Spaced Repetition** | Boost as refresher | Boost for reinforcement | Boost for connections |
| **Completion Checks** | Include in mini-quizzes | — | — |

### Learn Mode Context

The AI uses relationships to provide contextual introductions:

```typescript
function buildLearnModeContext(ip: InformationPoint): string {
  const prereqTitles = ip.prerequisites.map(id => getIP(id).title);
  const dependentTitles = ip.dependents.map(id => getIP(id).title);
  const relatedTitles = ip.relatedPoints.map(id => getIP(id).title);
  
  return `
    Prerequisites (building on): ${prereqTitles.join(', ') || 'None'}
    Leads to: ${dependentTitles.join(', ') || 'None'}
    Related concepts: ${relatedTitles.join(', ') || 'None'}
  `;
}
```

### Spaced Repetition Boost

When an IP is due for review, related IPs get priority boosts:

```typescript
interface RelationshipBoost {
  prerequisites: 0.1;    // Refresh foundational knowledge
  dependents: 0.05;      // Reinforce downstream concepts
  relatedPoints: 0.08;   // Strengthen lateral connections
}
```

### Comparison Questions

Related IPs enable comparison quiz questions (see [Question Generation](./question-generation.md)):

```typescript
interface ComparisonQuestion {
  type: 'comparison';
  ipIds: [string, string];
  format: 'multiple_choice' | 'question_answer';
  
  // Examples:
  // "What is the key difference between Stack and Queue?"
  // "How does Binary Search improve on Linear Search?"
}
```

### AI Generation of Relationships

When AI generates IPs, it also identifies relationships:

```typescript
const RELATIONSHIP_PROMPT = `
For each Information Point, identify:
1. prerequisites: Which previously defined IPs must be understood first?
2. relatedPoints: Which IPs are conceptually similar (for comparison)?

Consider:
- Prerequisites create a learning sequence
- Related points are peers (same category, alternatives, comparisons)
- An IP can be a prerequisite WITHOUT being related (and vice versa)
`;
```

---

## IP Generation Pipeline

### From Course Creation

```
┌─────────────────────────────────────────────────────────────────┐
│  IP GENERATION PIPELINE                                         │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  User provides: Topic + (optional) materials + goals            │
│         │                                                       │
│         ▼                                                       │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │  1. Course Structure Generation                             ││
│  │     AI proposes: Modules → Lessons                          ││
│  └──────────────────────────┬──────────────────────────────────┘│
│                             │                                   │
│                             ▼                                   │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │  2. IP Generation (per Lesson)                              ││
│  │     AI generates: title, type, content, prerequisites       ││
│  └──────────────────────────┬──────────────────────────────────┘│
│                             │                                   │
│                             ▼                                   │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │  3. Quiz Type Assignment                                    ││
│  │     AI assigns appropriate quiz types per IP                ││
│  └──────────────────────────┬──────────────────────────────────┘│
│                             │                                   │
│                             ▼                                   │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │  4. User Review (optional)                                  ││
│  │     Human can edit, reorder, add assets, override types     ││
│  └─────────────────────────────────────────────────────────────┘│
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Generation Prompt

```typescript
const IP_GENERATION_PROMPT = `
Generate Information Points for this lesson.

Lesson: {lessonTitle}
Module: {moduleTitle}
Course: {courseTitle}
Learning Objectives: {objectives}
Previous IPs in course: {previousIPSummaries}

For each IP, provide:
1. title: Clear, concise name
2. type: definition | concept | procedure | example
3. content: Markdown content (use {{asset:placeholder}} for suggested visuals)
4. prerequisites: IDs of IPs this builds on (from previous list)
5. suggestedAssets: Description of helpful images/diagrams

Return as JSON array. Order IPs for pedagogical progression.
Each IP should be atomic—one clear idea per point.
`;
```

---

## Mobile Optimization

| Strategy | Implementation |
|----------|----------------|
| **Lazy loading** | Images load on scroll into view |
| **Thumbnails** | Show low-res first, full on tap |
| **Progressive** | Stream video/audio, no preload |
| **Offline cache** | Cache text + thumbnails locally |
| **Data saver** | Option to hide media until requested |

---

## Infrastructure

This system relies on **Google Cloud** infrastructure:

| Service | Use |
|---------|-----|
| **Google Cloud Storage** | Media assets (images, audio, diagrams) |
| **Gemini 2.5 Flash** | IP generation, transcription, image descriptions, quiz type assignment |
| **YouTube** | External video hosting |

Upgrade to Gemini 3 Flash when available.

