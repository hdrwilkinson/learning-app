# Information Point Generation

<!--
Status: Draft
Created: 2025-11-30
Issue: #15 (Q3, Q4, Q5)
Owner: Harry
-->

> System specification for AI-generated Information Points, content formats, and quiz type assignment.

## Related Specifications

| Spec                                                              | Relationship                        |
| ----------------------------------------------------------------- | ----------------------------------- |
| [Question Generation](./question-generation.md)                   | Uses IPs to generate quiz questions |
| [Learning & Interaction Modes](./learning-interaction-modes.md)   | Modes that present IP content       |
| [Course Structure & Navigation](./course-structure-navigation.md) | Hierarchy containing IPs            |

> **Database Schema:** See [Database Schema Reference](/docs/reference/database-schema) for complete data model definitions.

## Overview

Information Points (IPs) are the atomic units of learning content. They are primarily generated by AI when courses are created, with human override capabilities.

### Core Principles

1. **AI-first**: IPs generated automatically from course topics/materials
2. **Rich content**: Support for text, code, math, and media
3. **Efficient AI context**: Media stored externally, AI receives text descriptions
4. **Flexible quiz types**: AI assigns appropriate quiz types, humans can override

---

## Content Model

### Hybrid Storage Approach

| Content Type    | Storage              | AI Processing    |
| --------------- | -------------------- | ---------------- |
| Text (Markdown) | Database             | Direct           |
| Code blocks     | Database             | Direct           |
| LaTeX/Math      | Database (source)    | Direct           |
| Images          | Google Cloud Storage | Description only |
| Audio           | Google Cloud Storage | Transcript only  |
| Diagrams        | Google Cloud Storage | Description only |
| Videos          | YouTube (external)   | Transcript only  |

### Data Model

> **Note:** See [Database Schema Reference](/docs/reference/database-schema) for complete Prisma model definitions.

```typescript
interface InformationPoint {
    id: string;
    lessonId: string;
    order: number;

    // Metadata
    title: string;
    typeId: string; // References InformationPointType lookup table

    // Content (Markdown with asset placeholders)
    content: string; // e.g., "Binary search:\n\n{{asset:diagram-123}}\n\nSteps:..."
}

// Prerequisites stored in InformationPointPrerequisite junction table
// Available quiz types stored in InformationPointQuizType junction table
// Assets deferred to future implementation
```

### Asset Model

```typescript
interface Asset {
    id: string;
    informationPointId: string;

    type: "image" | "video" | "audio" | "diagram";

    // Storage
    storage: {
        provider: "gcs" | "youtube";
        url: string;
        thumbnailUrl?: string;
    };

    // For AI (no media processing needed)
    aiMetadata: {
        description: string; // Auto-generated or manual
        transcript?: string; // For video/audio
        altText?: string; // Accessibility
    };

    // Rendering hints
    display: {
        position: "inline" | "block";
        caption?: string;
        aspectRatio?: string;
    };

    // Metadata
    fileSize?: number;
    duration?: number; // For video/audio (seconds)
    generatedAt?: Date; // When AI metadata was generated
}
```

---

## AI Context Generation

When AI needs to understand an IP (for Learn Mode, Quiz generation, etc.), we build a **text-only context**:

```typescript
function buildAIContext(ip: InformationPoint): string {
    let context = ip.content;

    for (const asset of ip.assets) {
        const placeholder = `{{asset:${asset.id}}}`;
        let replacement = `[${asset.type.toUpperCase()}: ${asset.aiMetadata.description}]`;

        if (asset.aiMetadata.transcript) {
            replacement += `\n[Transcript: ${asset.aiMetadata.transcript}]`;
        }

        context = context.replace(placeholder, replacement);
    }

    return context;
}
```

**Example transformation:**

```markdown
// Original content
Binary search divides the search space in half repeatedly.

{{asset:diagram-bsearch-001}}

Here's the algorithm:
```

```markdown
// AI context
Binary search divides the search space in half repeatedly.

[DIAGRAM: Sorted array with left, mid, right pointers. Shows 3 iterations
narrowing down to find target value 7. Arrows indicate comparison direction.]

Here's the algorithm:
```

---

## Asset Processing Pipeline

### On Upload

```
┌─────────────────────────────────────────────────────────────────┐
│  ASSET UPLOAD PIPELINE                                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  User uploads file                                              │
│         │                                                       │
│         ▼                                                       │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │  1. Upload to Google Cloud Storage                          ││
│  │     → Returns URL + thumbnailUrl                            ││
│  └──────────────────────────┬──────────────────────────────────┘│
│                             │                                   │
│                             ▼                                   │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │  2. Generate AI Metadata (async)                            ││
│  │                                                             ││
│  │  Image/Diagram → Gemini Vision → description                ││
│  │  Video → YouTube transcript OR Gemini 2.5 Flash → transcript││
│  │  Audio → Gemini 2.5 Flash → transcript                      ││
│  └──────────────────────────┬──────────────────────────────────┘│
│                             │                                   │
│                             ▼                                   │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │  3. Store Asset record with aiMetadata                      ││
│  │     → Regenerate parent IP's aiContext                      ││
│  └─────────────────────────────────────────────────────────────┘│
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Model Configuration

```typescript
const ASSET_AI_CONFIG = {
    imageDescription: {
        model: "gemini-2.5-flash", // Vision capable
        prompt: `Describe this image for a learning context. 
             Focus on educational content, diagrams, and key visual elements.
             Be concise but comprehensive.`,
        maxTokens: 256,
    },

    audioTranscription: {
        model: "gemini-2.5-flash",
        maxDuration: 600, // 10 minutes max
    },

    videoTranscription: {
        // Prefer YouTube auto-captions if available
        fallbackModel: "gemini-2.5-flash",
        maxDuration: 1800, // 30 minutes max
    },
};
```

---

## Quiz Type Assignment

### Default: AI Assignment

When an IP is created, AI analyzes content and assigns appropriate quiz types:

```typescript
interface QuizTypeAssignment {
    rules: {
        // Definitions → good for T/F and MC
        definition: ["binary", "multiple_choice"];

        // Concepts → all types work
        concept: ["binary", "multiple_choice", "question_answer"];

        // Procedures → Q&A best for explaining steps
        procedure: ["multiple_choice", "question_answer"];

        // Examples → MC for recognition
        example: ["multiple_choice"];
    };
}
```

### AI Assignment Prompt

```typescript
const QUIZ_TYPE_PROMPT = `
Analyze this Information Point and determine which quiz types are appropriate.

Information Point:
Title: {title}
Type: {type}
Content: {aiContext}

Consider:
- Binary (True/False): Good for facts, definitions, clear statements
- Multiple Choice: Good for recognition, comparison, selecting correct options
- Question & Answer: Good for explanation, procedures, deeper understanding

Return JSON: { "quizTypes": ["binary", "multiple_choice", "question_answer"] }
Only include types that genuinely fit this content.
`;
```

### Human Override

```typescript
interface QuizTypeOverride {
    // Human directly sets types
    manual: (ipId: string, types: QuizType[]) => void;

    // Human requests AI suggestion, then reviews
    requestSuggestion: (ipId: string) => Promise<QuizType[]>;
    approveSuggestion: (ipId: string, types: QuizType[]) => void;
}
```

---

## IP Relationships

Information Points have prerequisite relationships that power contextual learning.

> **Database Schema:** Prerequisites are stored in the `InformationPointPrerequisite` junction table. See [Database Schema Reference](/docs/reference/database-schema).

### Relationship Types

| Type            | Direction | Storage  | Description                              |
| --------------- | --------- | -------- | ---------------------------------------- |
| `prerequisites` | Backward  | Stored   | IPs that must be learned before this one |
| `dependents`    | Forward   | Computed | IPs that build on this one               |

### Computing Dependents

`dependents` is derived from `prerequisites` by querying the junction table:

```typescript
async function getDependents(ipId: string): Promise<string[]> {
    // Find all IPs where this IP is their prerequisite
    return await db.informationPointPrerequisite
        .findMany({
            where: { prerequisiteId: ipId },
            select: { dependentId: true },
        })
        .then((rows) => rows.map((row) => row.dependentId));
}

// Can be cached and invalidated when course structure changes
```

### Usage by Feature

| Feature               | Prerequisites           | Dependents              |
| --------------------- | ----------------------- | ----------------------- |
| **Learn Mode**        | "Building on X..."      | "This enables Y..."     |
| **Spaced Repetition** | Boost as refresher      | Boost for reinforcement |
| **Completion Checks** | Include in mini-quizzes | —                       |

### Learn Mode Context

The AI uses relationships to provide contextual introductions:

```typescript
async function buildLearnModeContext(ip: InformationPoint): Promise<string> {
    const prereqs = await getPrerequisites(ip.id);
    const dependents = await getDependents(ip.id);

    const prereqTitles = prereqs.map((p) => p.title);
    const dependentTitles = dependents.map((d) => d.title);

    return `
    Prerequisites (building on): ${prereqTitles.join(", ") || "None"}
    Leads to: ${dependentTitles.join(", ") || "None"}
  `;
}
```

### Spaced Repetition Boost

When an IP is due for review, prerequisite IPs get priority boosts:

```typescript
interface RelationshipBoost {
    prerequisites: 0.1; // Refresh foundational knowledge
    dependents: 0.05; // Reinforce downstream concepts
}
```

### AI Generation of Relationships

When AI generates IPs, it also identifies prerequisites:

```typescript
const RELATIONSHIP_PROMPT = `
For each Information Point, identify:
1. prerequisites: Which previously defined IPs must be understood first?

Consider:
- Prerequisites create a learning sequence
- Example: "Words" requires "Letters" as a prerequisite
`;
```

---

## IP Generation Pipeline

### From Course Creation

```
┌─────────────────────────────────────────────────────────────────┐
│  IP GENERATION PIPELINE                                         │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  User provides: Topic + (optional) materials + goals            │
│         │                                                       │
│         ▼                                                       │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │  1. Course Structure Generation                             ││
│  │     AI proposes: Modules → Lessons                          ││
│  └──────────────────────────┬──────────────────────────────────┘│
│                             │                                   │
│                             ▼                                   │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │  2. IP Generation (per Lesson)                              ││
│  │     AI generates: title, type, content, prerequisites       ││
│  └──────────────────────────┬──────────────────────────────────┘│
│                             │                                   │
│                             ▼                                   │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │  3. Quiz Type Assignment                                    ││
│  │     AI assigns appropriate quiz types per IP                ││
│  └──────────────────────────┬──────────────────────────────────┘│
│                             │                                   │
│                             ▼                                   │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │  4. User Review (optional)                                  ││
│  │     Human can edit, reorder, add assets, override types     ││
│  └─────────────────────────────────────────────────────────────┘│
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Generation Prompt

```typescript
const IP_GENERATION_PROMPT = `
Generate Information Points for this lesson.

Lesson: {lessonTitle}
Module: {moduleTitle}
Course: {courseTitle}
Learning Objectives: {objectives}
Previous IPs in course: {previousIPSummaries}

For each IP, provide:
1. title: Clear, concise name
2. type: definition | concept | procedure | example
3. content: Markdown content (use {{asset:placeholder}} for suggested visuals)
4. prerequisites: IDs of IPs this builds on (from previous list)
5. suggestedAssets: Description of helpful images/diagrams

Return as JSON array. Order IPs for pedagogical progression.
Each IP should be atomic—one clear idea per point.
`;
```

---

## Mobile Optimization

| Strategy          | Implementation                       |
| ----------------- | ------------------------------------ |
| **Lazy loading**  | Images load on scroll into view      |
| **Thumbnails**    | Show low-res first, full on tap      |
| **Progressive**   | Stream video/audio, no preload       |
| **Offline cache** | Cache text + thumbnails locally      |
| **Data saver**    | Option to hide media until requested |

---

## Infrastructure

This system relies on **Google Cloud** infrastructure:

| Service                  | Use                                                                    |
| ------------------------ | ---------------------------------------------------------------------- |
| **Google Cloud Storage** | Media assets (images, audio, diagrams)                                 |
| **Gemini 2.5 Flash**     | IP generation, transcription, image descriptions, quiz type assignment |
| **YouTube**              | External video hosting                                                 |

Upgrade to Gemini 3 Flash when available.
